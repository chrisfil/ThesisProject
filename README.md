# ThesisProject
Code and material used for my thesis project, "Singing voice separation using Interpretable Deep Learning"

The notebooks were used for the experiments.
The python scripts in experiment folder are used for training, evaluation, editing, separation, reconstructing the estimated audio, concatanating audio, etc.

The anaconda environment is also provided in env.yaml, with all the dependencies.


APNet and AttProtos folders include the code from these works with some minor modifications for thesis purposes:

Zinemanas, P., Rocamora, M., Fonseca, E., Font, F. & Serra, X. Toward interpretable polyphonic sound event detection with attention maps based on local prototypes. In Proceedings of the Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE) (2021). 

Zinemanas, P., Rocamora, M., Miron, M., Font, F. and Serra, X. An Interpretable Deep Learning Model for Automatic Sound Classification. Electronics, 10(7), 850 (2021).
